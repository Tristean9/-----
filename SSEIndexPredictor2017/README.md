# 《深度学习模型与应用》个人作业三 第一题 对上证指数进行建模和验证

## 项目说明

本项目旨在完成《深度学习模型与应用》个人作业三 中的第一题“对上证指数进行建模和验证”。

- **数据预处理**：笔者使用pandas和sklearn这两个包来对数据进行预处理和Dataloader构建，以符合pytorch的输入要求，最终形成训练集、验证集和测试集。
- **框架和模型选择**：笔者使用pytorch框架，选用LSTM模型和GRU模型进行模型搭建和训练，主题思路是从序列（时间滑动窗口）到序列（预测时间的长度）
- **超参数调整**：笔者使用optuna，以最小化均方误差为目标，制定好包括批次处理大小，隐藏层数，隐藏层维度，学习率，滑动窗口长度这几个超参数的搜索空间，在LSTM和GRU这两个模型上进行超参数调整。
- **测试集评估**：笔者选用均方误差， 均方根误差，平均均对误差，R-Squared和方向准确性来对模型在测试集上的性能进行评估

## 项目结构

```text
SSEIndexPredictor2017
├── data_preprocessing.py         # 脚本用于预处理数据和Dataloader构建
├── engine.py                     # 引擎脚本，负责模型的训练，调参和评估流程
├── main.py                       # 主脚本，项目的入口点
├── model.py                      # 包含预测模型定义的脚本
├── ModelTrainingLifecycle        # 记录模型训练生命周期的日志
├── README.md                     # 项目的README文件，描述项目信息和启动指南
├── data                          # 数据目录，存放项目数据文件
│   └── SSE_data.csv              # 上证指数数据集
└── trained_models                # 训练模型目录，存放训练后的模型文件
    ├── best_model.pth            # 训练后的模型权重文件
    └── best_model_params.json    # 训练后的模型超参数文件
```

## 运行说明

在安装好相关依赖后，进入`SSEIndexPredictor2017`目录，直接运行 `main.py`脚本即可

## 模型介绍

**LSTM（长短期记忆网络）**：是一种特殊类型的循环神经网络（RNN），专门设计来解决传统RNN在处理长序列数据时遇到的梯度消失或梯度爆炸问题。LSTM通过引入一个复杂的单元结构，其中包含三个门（输入门、遗忘门和输出门），以及一个维持长期状态的单元，能够更好地学习长距离的依赖关系。这些门控制着信息的流入、存储和流出，让网络有选择性地记忆或忘记信息，从而在涉及时间序列预测、自然语言处理等领域展现出了强大的性能。

**GRU（门控循环单元）**：是另一种流行的RNN变体，旨在简化LSTM模型而设计，它合并了LSTM中的遗忘门和输入门为一个更新门，同时使用了一个重置门。GRU的结构比LSTM简洁，因此它的参数更少，训练速度通常更快，同时在很多情况下能够提供与LSTM相当的性能。由于其结构上的简化，GRU模型在处理短序列数据时表现得尤为出色，且更容易训练，广泛应用于语言模型、机器翻译等领域。

## 结果评价

笔者使用optuna，以最小化均方误差为目标，制定好包括批次处理大小，隐藏层数，隐藏层维度，学习率，滑动窗口长度这几个超参数的搜索空间，在LSTM和GRU这两个模型上进行超参数调整。

定义的参数网络为：

```python
batch_size = trial.suggest_categorical("batch_size", [16, 32, 64, 128])  
num_layers = trial.suggest_int("num_layers", 1, 3)   # 可选范围: 1 到 3
hidden_dim = trial.suggest_categorical("hidden_dim", [64, 128, 256])  
lr = trial.suggest_float("lr", 1e-4, 1e-2, log=True) # 可选范围: 0.0001 到 0.01 (对数刻度)
model_choice = trial.suggest_categorical("model", ["LSTM", "GRU"])
tw = trial.suggest_categorical("tw", [40, 50, 60])
```

每个模型训练20个轮次，在100中参数组合中，找到的最优模型参数为：

```json
{
    "batch_size": 64,
    "num_layers": 1,
    "hidden_dim": 128,
    "lr": 0.00015453299584413898,
    "model": "GRU",
    "tw": 50
}
```

该最优模型的预测值和真实值分别为：

```text
Preds       Values
2783.859          3105.309
2843.834          3133.787
2979.731          3157.906
2890.152          3163.776
2967.663          3148.532
3008.363          3167.570
3018.796          3156.686
3100.806          3133.602
3039.804          3116.083
3060.497          3104.492
3090.150          3087.030
3092.376          3104.766
3040.820          3104.971
3068.799          3095.819
3092.396          3125.421
3090.654          3134.592
3069.703          3137.646
3115.315          3149.217
3132.954          3160.082
3034.917          3143.093
3124.097          3154.405
3073.514          3148.086
3099.103          3164.688
3079.108          3183.007
```

笔者选用均方误差， 均方根误差，平均决对误差，R-Squared和方向准确性来对该最优模型在测试集上的性能进行评估。结果为：

```text
MSE: 17822.189453125
RMSE: 133.49977111816
MAE: 99.5581283569336
方向准确性: 0.5217391304347826
```

综合预测值和真实值的数据以及提供的性能指标，该模型在测试集上展现了一定的预测准确度，但同时也揭示出了其预测性能的局限性。均方误差（MSE）、均方根误差（RMSE）和平均绝对误差（MAE）指标表明，模型的预测与实际值之间存在一定程度的偏差，这可能是由数据本身的比较简单，预测序列较长和模型的不足造成的。方向准确性稍高于随机水平，这说明模型对趋势的把握有一定的准确性，但对于可能需要高预测准确度的任务来说，性能仍需提升。总体来说，这些结果表明该模型对数据有一定的理解能力，但对于预测任务还有较大的优化空间。

(注意：完整的训练过程和结果可见ModelTrainingLifecycle.log)
